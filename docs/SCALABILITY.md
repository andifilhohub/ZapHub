# ğŸ“Š Guia de Escalabilidade - ZapHub

## âœ… Arquitetura Multi-Tenancy

O ZapHub foi projetado para suportar **mÃºltiplos clientes** em uma Ãºnica instalaÃ§Ã£o:

### ğŸ”’ Isolamento por Cliente

```
auth_data/
â”œâ”€â”€ cliente-uuid-1/     â† SessÃ£o do Cliente 1
â”‚   â”œâ”€â”€ creds.json
â”‚   â”œâ”€â”€ app-state-sync-key-*.json
â”‚   â””â”€â”€ pre-key-*.json
â”œâ”€â”€ cliente-uuid-2/     â† SessÃ£o do Cliente 2
â”‚   â”œâ”€â”€ creds.json
â”‚   â””â”€â”€ ...
â””â”€â”€ cliente-uuid-N/     â† SessÃ£o do Cliente N
    â””â”€â”€ ...
```

Cada cliente tem:
- âœ… **Auth data isolado** (pasta prÃ³pria)
- âœ… **WebSocket prÃ³prio** (Map<sessionId, socket>)
- âœ… **Registro no banco** (UUID Ãºnico)
- âœ… **Fila de mensagens** separada

---

## ğŸ“ˆ Tiers de Escalabilidade

### ğŸ¢ Tier 1: Pequeno Porte (1-50 clientes)

**Hardware Recomendado:**
- **CPU**: 2-4 cores
- **RAM**: 4-8GB
- **Disco**: 20GB SSD
- **Rede**: 100Mbps

**ConfiguraÃ§Ã£o (.env):**
```env
NODE_ENV=production
MAX_CONCURRENT_SESSIONS=50
DB_POOL_MAX=20
QUEUE_CONCURRENCY=10
```

**Custos Estimados (VPS):**
- AWS t3.medium: ~$30/mÃªs
- DigitalOcean: ~$24/mÃªs
- Hetzner: ~â‚¬10/mÃªs

---

### ğŸ­ Tier 2: MÃ©dio Porte (50-200 clientes)

**Hardware Recomendado:**
- **CPU**: 4-8 cores
- **RAM**: 16-32GB
- **Disco**: 100GB SSD NVMe
- **Rede**: 1Gbps

**ConfiguraÃ§Ã£o (.env):**
```env
NODE_ENV=production
MAX_CONCURRENT_SESSIONS=200
DB_POOL_MAX=50
DB_POOL_MIN=10
QUEUE_CONCURRENCY=20
REDIS_POOL_MAX=20
```

**OtimizaÃ§Ãµes:**
```bash
# Aumentar file descriptors
ulimit -n 65536

# PostgreSQL tuning
shared_buffers = 4GB
effective_cache_size = 12GB
max_connections = 200
```

**Custos Estimados:**
- AWS c6i.2xlarge: ~$200/mÃªs
- DigitalOcean Premium: ~$160/mÃªs

---

### ğŸ—ï¸ Tier 3: Grande Porte (200-1000+ clientes)

**Arquitetura: Horizontal Scaling**

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Load Balancer  â”‚
                    â”‚   (NGINX/HAProxy)â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚               â”‚               â”‚
         â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
         â”‚ API +   â”‚    â”‚ API +   â”‚    â”‚ API +   â”‚
         â”‚ Worker 1â”‚    â”‚ Worker 2â”‚    â”‚ Worker Nâ”‚
         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
              â”‚               â”‚               â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                            â”‚
           â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
           â”‚PostgreSQLâ”‚              â”‚   Redis     â”‚
           â”‚(Primary) â”‚              â”‚  (Cluster)  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Requisitos por InstÃ¢ncia:**
- **CPU**: 8 cores
- **RAM**: 32GB
- **Disco**: 200GB SSD
- **SessÃµes por instÃ¢ncia**: 200-300

**Shared Services:**
- **PostgreSQL**: Primary + 2 Replicas (Read-only)
- **Redis**: Cluster 3 nodes
- **Storage**: S3 ou equivalente para `auth_data`

**ConfiguraÃ§Ã£o:**
```env
# Cada instÃ¢ncia
MAX_CONCURRENT_SESSIONS=300
DB_POOL_MAX=30
QUEUE_CONCURRENCY=15

# Usar S3 para auth_data (implementar)
AUTH_DATA_STORAGE=s3
AUTH_DATA_S3_BUCKET=zaphub-auth-data
```

---

## ğŸ“Š Monitoramento de Capacidade

### API Endpoint: GET /api/v1/sessions/stats

```bash
curl http://localhost:3000/api/v1/sessions/stats
```

**Resposta:**
```json
{
  "success": true,
  "data": {
    "capacity": {
      "active": 45,
      "max": 100,
      "available": 55,
      "usage_percent": 45.00
    },
    "sessions_by_status": {
      "connected": 45,
      "qr_pending": 3,
      "disconnected": 12,
      "failed": 2
    },
    "limits": {
      "db_pool_max": 20,
      "queue_concurrency": 10
    }
  }
}
```

### Alertas Recomendados:

- âš ï¸ **usage_percent > 80%**: Preparar para escalar
- ğŸš¨ **usage_percent > 95%**: Escalar URGENTE
- ğŸ”´ **active >= max**: SessÃµes bloqueadas

---

## ğŸ¯ Limites e Gargalos

### 1. **MemÃ³ria RAM**
- **Cada sessÃ£o**: 10-30MB
- **100 sessÃµes**: ~3GB
- **1000 sessÃµes**: ~30GB

**SoluÃ§Ã£o**: Horizontal scaling (mÃºltiplas instÃ¢ncias)

### 2. **WebSocket Connections**
- **Limite Linux**: File descriptors
- **PadrÃ£o**: 1024 FDs
- **Recomendado**: 65536+ FDs

```bash
# Permanente: /etc/security/limits.conf
* soft nofile 65536
* hard nofile 65536
```

### 3. **Database Connections**
- **Pool padrÃ£o**: 10 conexÃµes
- **Recomendado Tier 2**: 50 conexÃµes
- **Recomendado Tier 3**: Connection pooler (PgBouncer)

### 4. **Redis**
- **Filas BullMQ**: Pode saturar Redis
- **SoluÃ§Ã£o**: Redis Cluster ou mÃºltiplas instÃ¢ncias

---

## ğŸ”§ Tuning de Performance

### PostgreSQL:
```sql
-- postgresql.conf
shared_buffers = 4GB
effective_cache_size = 12GB
maintenance_work_mem = 512MB
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 100
random_page_cost = 1.1  -- Para SSD
effective_io_concurrency = 200
max_worker_processes = 8
max_parallel_workers_per_gather = 4
max_parallel_workers = 8
```

### Node.js:
```bash
# Aumentar heap size
NODE_OPTIONS="--max-old-space-size=4096"

# MÃºltiplos workers (cluster mode)
PM2_INSTANCES=4
```

### Redis:
```conf
# redis.conf
maxmemory 2gb
maxmemory-policy allkeys-lru
```

---

## ğŸ“¦ Deploy com Docker Compose (Tier 2)

```yaml
version: '3.8'

services:
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: zaphub
      POSTGRES_USER: zaphub
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - pgdata:/var/lib/postgresql/data
    shm_size: 1gb

  redis:
    image: redis:7-alpine
    command: redis-server --maxmemory 2gb --maxmemory-policy allkeys-lru
    volumes:
      - redisdata:/data

  zaphub-api:
    build: .
    environment:
      NODE_ENV: production
      MAX_CONCURRENT_SESSIONS: 200
      DB_POOL_MAX: 50
    volumes:
      - ./auth_data:/app/auth_data
    ports:
      - "3000:3000"
    depends_on:
      - postgres
      - redis
    deploy:
      replicas: 3  # 3 instÃ¢ncias
      resources:
        limits:
          cpus: '2'
          memory: 8G

volumes:
  pgdata:
  redisdata:
```

---

## ğŸ“ˆ Roadmap de Melhorias

### Curto Prazo (1-3 meses):
- [ ] Implementar health checks (`/health`)
- [ ] Metrics (Prometheus/Grafana)
- [ ] Rate limiting por sessÃ£o
- [ ] Retry inteligente para mensagens

### MÃ©dio Prazo (3-6 meses):
- [ ] Storage S3 para `auth_data`
- [ ] Session affinity (sticky sessions)
- [ ] Auto-scaling baseado em mÃ©tricas
- [ ] Backup automÃ¡tico de sessÃµes

### Longo Prazo (6-12 meses):
- [ ] Multi-region deployment
- [ ] Session migration entre workers
- [ ] WebSocket proxy para reduzir conexÃµes
- [ ] Message batching para otimizar envios

---

## ğŸ›¡ï¸ SeguranÃ§a em Escala

### Isolamento de Clientes:
```javascript
// Cada cliente NUNCA pode:
// - Acessar mensagens de outro cliente
// - Ver QR code de outro cliente
// - Interferir em outras sessÃµes

// Implementado via:
// - API Key por sessÃ£o (opcional)
// - Row-level security no PostgreSQL
// - ValidaÃ§Ã£o de sessionId em todos endpoints
```

### Rate Limiting:
```javascript
// Implementar limites por cliente
const LIMITS = {
  messages_per_minute: 60,
  messages_per_hour: 1000,
  messages_per_day: 10000,
};
```

---

## ğŸ’° Estimativa de Custos

| Clientes | Tier | Hardware | Custo/MÃªs |
|----------|------|----------|-----------|
| 1-50     | 1    | 4GB RAM  | $25-50    |
| 50-200   | 2    | 16GB RAM | $100-200  |
| 200-500  | 3    | 3x8GB    | $300-500  |
| 500-1000 | 3    | 5x16GB   | $800-1200 |
| 1000+    | 3    | Custom   | $2000+    |

---

## ğŸ“ ConclusÃ£o

O ZapHub **jÃ¡ suporta** multi-tenancy desde o design inicial:

âœ… **Sim, pode atender centenas de clientes** na mesma instalaÃ§Ã£o
âœ… **Sim, cada cliente tem auth_data isolado**
âœ… **Sim, escala horizontalmente** com load balancer
âœ… **Limite atual**: 100 sessÃµes simultÃ¢neas (configurÃ¡vel)

**Para produÃ§Ã£o:**
1. Configure `MAX_CONCURRENT_SESSIONS` apropriado
2. Monitore `/api/v1/sessions/stats`
3. Escale horizontalmente quando usage > 80%
4. Use PostgreSQL tuning para Tier 2+
5. Implemente Redis Cluster para Tier 3

**PrÃ³ximos passos recomendados:**
- Implementar health checks
- Configurar Prometheus/Grafana
- Testar load testing com 100+ sessÃµes
- Documentar procedures de backup/restore
